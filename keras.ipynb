{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982831d1",
   "metadata": {},
   "source": [
    "# Keras\n",
    "It is a high-level deep learning API written in Python by Google, designed to make building and experimenting with neural networks fast, easy, and intuitive. It acts as an interface for the TensorFlow library, but it can also run on top of other backends like Theano and Microsoft Cognitive Toolkit (CNTK), though TensorFlow is now the default and most supported backend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f7671",
   "metadata": {},
   "source": [
    "**Key Features of Keras**\n",
    "- User-friendly: Simple API that minimizes the number of user actions required for common use cases.\n",
    "- Modular: Neural networks are built by plugging together building blocks like layers, optimizers, and activation functions.\n",
    "- Extensible: Easily add new modules or custom components.\n",
    "- Pythonic: Follows Python conventions and practices, making it readable and easy to debug.\n",
    "- Integrated with TensorFlow: Keras is now part of TensorFlow and accessible via tf.keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0b4c9",
   "metadata": {},
   "source": [
    "**Core Components of Keras**\n",
    "1. Models\n",
    "\n",
    "Keras provides two main ways to define a model:\n",
    "- Sequential – Linear stack of layers.\n",
    "- Model (Functional API) – More flexible, supports complex architectures like multi-input/output.\n",
    "2. Layers\n",
    "\n",
    "Each Layer in Keras is like a transformation function. For example:\n",
    "- Dense(units, activation): Fully connected layer.\n",
    "- Conv2D(filters, kernel_size): Used in image processing.\n",
    "- LSTM(units): Used for sequence data like time series or text.\n",
    "\n",
    "Each layer has:\n",
    "- weights (learned during training)\n",
    "- activation function (adds non-linearity)\n",
    "- input/output shape\n",
    "\n",
    "3. Activation Functions\n",
    "They define how the weighted sum of the input is transformed before being passed to the next layer.\n",
    "- relu: For hidden layers (fast and efficient).\n",
    "- sigmoid: For binary classification.\n",
    "- softmax: For multi-class classification.\n",
    "- tanh: Alternative to sigmoid, but zero-centered.\n",
    "\n",
    "4. Loss Functions\n",
    "\n",
    "Used to measure the difference between actual and predicted values.\n",
    "- binary_crossentropy: For binary classification.\n",
    "- ategorical_crossentropy: For multi-class (one-hot encoded).\n",
    "- sparse_categorical_crossentropy: For multi-class (integers as labels).\n",
    "- mse (mean squared error): For regression tasks.\n",
    "\n",
    "5. Optimizers\n",
    "\n",
    "These define how the model weights are updated based on the loss.\n",
    "- Adam: Adaptive learning rate; works well in most cases.\n",
    "- SGD: Stochastic gradient descent (basic and fast).\n",
    "- RMSprop: Useful in RNNs and sequence models.\n",
    "\n",
    "5. Metrics\n",
    "\n",
    "Used to evaluate performance.\n",
    "- accuracy: Classification.\n",
    "- mae: Mean Absolute Error (regression).\n",
    "- mse: Mean Squared Error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82cb014",
   "metadata": {},
   "source": [
    "*Use Cases of Keras*\n",
    "- Image classification\n",
    "- Natural language processing\n",
    "- Time series forecasting\n",
    "- Recommender systems\n",
    "- Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc296c",
   "metadata": {},
   "source": [
    "**Basic Keras Workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8be119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6991 - accuracy: 0.4780\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.4680\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4750\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4920\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.4910\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.4960\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5210: 0s - loss: 0.6917 - accuracy: 0.53\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6920 - accuracy: 0.5130\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.5230\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x180f940bac0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define a simple model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=(10,)),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Dummy data\n",
    "import numpy as np\n",
    "X_train = np.random.rand(1000, 10)\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca006613",
   "metadata": {},
   "source": [
    "**Example: Binary Classification of Breast Cancer**\n",
    "\n",
    "We’ll use the Breast Cancer Wisconsin dataset (available in sklearn) to classify tumors as benign or malignant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5efc802",
   "metadata": {},
   "source": [
    "1. Load Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e58e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a068eb3",
   "metadata": {},
   "source": [
    "2. Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b5a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# print(data.shape)\n",
    "# data.head()\n",
    "\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62fdda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=80)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a858df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data  \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffbfea3",
   "metadata": {},
   "source": [
    "3. Define and Train a Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d6d412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0f606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0669883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "model = Sequential([\n",
    "    Dense(30, activation = 'relu', input_shape=(X_train.shape[1], )), # Input layer with number of features\n",
    "    Dense(15, activation = 'relu'), # Neurons in hidden layer\n",
    "    Dense(1, activation = 'sigmoid') # Output layer for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3fe3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer = Adam(learning_rate = 0.001),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b0e76c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.3330 - accuracy: 0.9066 - val_loss: 0.2761 - val_accuracy: 0.8901\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2532 - accuracy: 0.9368 - val_loss: 0.2276 - val_accuracy: 0.9121\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2023 - accuracy: 0.9478 - val_loss: 0.1931 - val_accuracy: 0.9231\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1676 - accuracy: 0.9588 - val_loss: 0.1667 - val_accuracy: 0.9341\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1405 - accuracy: 0.9615 - val_loss: 0.1467 - val_accuracy: 0.9341\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1210 - accuracy: 0.9643 - val_loss: 0.1281 - val_accuracy: 0.9231\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1051 - accuracy: 0.9808 - val_loss: 0.1142 - val_accuracy: 0.9560\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0920 - accuracy: 0.9835 - val_loss: 0.1032 - val_accuracy: 0.9560\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0821 - accuracy: 0.9863 - val_loss: 0.0952 - val_accuracy: 0.9670\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0735 - accuracy: 0.9863 - val_loss: 0.0888 - val_accuracy: 0.9670\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0673 - accuracy: 0.9863 - val_loss: 0.0828 - val_accuracy: 0.9780\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0616 - accuracy: 0.9890 - val_loss: 0.0814 - val_accuracy: 0.9780\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0575 - accuracy: 0.9890 - val_loss: 0.0800 - val_accuracy: 0.9780\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0539 - accuracy: 0.9890 - val_loss: 0.0764 - val_accuracy: 0.9670\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9918 - val_loss: 0.0748 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x180fb7c83a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model \n",
    "model.fit(\n",
    "    X_train, y_train, epochs = 15, batch_size = 32,\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "532f0fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1448 - accuracy: 0.9561\n",
      "test accuracy:  0.9561\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'test accuracy:  {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924304ab",
   "metadata": {},
   "source": [
    "# CNNs and RNNs\n",
    "Here’s a curated list of popular pretrained CNNs and RNNs, where they're typically used, and how you can access them (especially via TensorFlow or PyTorch)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60cb57f",
   "metadata": {},
   "source": [
    "**Pretrained CNNs**\n",
    "\n",
    "These are trained on ImageNet (1.2 million labeled images across 1,000 categories) and are commonly used for image classification, object detection, segmentation, etc.\n",
    "| Model            | Size / Speed   | Accuracy  | Use Case                                     |\n",
    "| ---------------- | -------------- | --------- | -------------------------------------------- |\n",
    "| **VGG16/VGG19**  | Large, slow    | Moderate  | Simple structure, good for transfer learning |\n",
    "| **ResNet50/101** | Medium         | High      | Very deep network, great generalization      |\n",
    "| **MobileNetV2**  | Lightweight    | Good      | Mobile/web apps, low-resource devices        |\n",
    "| **EfficientNet** | Compact + fast | Very high | Best balance of speed & accuracy             |\n",
    "| **InceptionV3**  | Medium         | High      | Complex objects, fine-grained tasks          |\n",
    "| **DenseNet121**  | Small-medium   | High      | Feature reuse, strong performance           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde92c8",
   "metadata": {},
   "source": [
    "Using a pretrained CNN (TensorFlow / Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd06eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "model = ResNet50(weights='imagenet')  # Downloaded automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e18b77",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df2a1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import (\n",
    "    VGG16, VGG19, InceptionV3, MobileNetV2, DenseNet121, EfficientNetB0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d6c82",
   "metadata": {},
   "source": [
    "**Pretrained RNNs**\n",
    "\n",
    "Unlike CNNs, pretrained RNNs are often embedded in NLP-focused models rather than standalone. They’re used for tasks like sentiment analysis, translation, speech recognition, and time series prediction.\n",
    "\n",
    "| Model               | Type            | Use Case                                   | Notes                                    |\n",
    "| ------------------- | --------------- | ------------------------------------------ | ---------------------------------------- |\n",
    "| **Word2Vec + LSTM** | RNN + Embedding | Sentiment analysis, text classification    | Pretrained embeddings + RNN              |\n",
    "| **ELMo**            | 2-layer Bi-LSTM | Contextual word embeddings (NLP)           | Deep pretrained LSTM encoder             |\n",
    "| **Seq2Seq**         | LSTM/GRU        | Machine translation, text summarization    | Often custom-trained on translation data |\n",
    "| **Tacotron 2**      | LSTM + CNN      | Text-to-speech generation                  | Uses CNNs + RNNs                         |\n",
    "| **OpenNMT**         | LSTM            | Neural machine translation (multi-lingual) | PyTorch / TensorFlow                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32d9a68",
   "metadata": {},
   "source": [
    "**RNNs are now often replaced by Transformers**\n",
    "\n",
    "In modern NLP, RNNs are being replaced by Transformers like:\n",
    "\n",
    "| Transformer Model | Replaces RNN in | Pretrained? | Examples                   |\n",
    "| ----------------- | --------------- | ----------- | -------------------------- |\n",
    "| **BERT**          | Text encoding   | ✅           | Question answering, NER    |\n",
    "| **GPT**           | Text generation | ✅           | Chatbots, summarization    |\n",
    "| **T5 / BART**     | Seq2seq tasks   | ✅           | Translation, summarization |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16f54f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=300, input_length=100),  # Could load GloVe here\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cab618",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "161b17ce",
   "metadata": {},
   "source": [
    "**Summary Table**\n",
    "| Type  | Model Name    | Use Case                    | Pretrained in                 |\n",
    "| ----- | ------------- | --------------------------- | ----------------------------- |\n",
    "| CNN   | ResNet50      | Image classification        | `keras.applications`          |\n",
    "| CNN   | EfficientNet  | Mobile/web vision tasks     | `keras.applications`          |\n",
    "| RNN   | ELMo          | NLP tasks (contextual word) | `tensorflow-hub`              |\n",
    "| RNN   | Seq2Seq LSTM  | Translation, summarization  | `OpenNMT`, `Fairseq`          |\n",
    "| Combo | Tacotron 2    | Text-to-speech              | `NVIDIA DeepLearningExamples` |\n",
    "| NLP   | BERT, GPT, T5 | Replaces RNN in many tasks  | `HuggingFace Transformers`    |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
